# LLM 永続的メモリアーキテクチャ

[English](README.md)

> **"6万人規模の企業は、各人がコンテキストウィンドウを共有しないにもかかわらず協調して働いている。なぜLLMエージェントには同じことができないのか？"**

---

LLMエージェントの本質的な限界である「記憶の永続性」問題を解決するためのアーキテクチャ設計。脳科学の知見（LTP、睡眠中の記憶整理）をソフトウェア設計に応用し、既存技術のみで実装可能な現実的なソリューションを提案する。

---

## 問題の本質

### 現在のLLMエージェントの限界

1. **セッションごとのリセット** - 毎回「生まれ変わる」ため、経験の蓄積がない
2. **Lost in the Middle問題** - 100万トークンのコンテキストがあっても、実効的に使えるのは一部のみ
3. **サイレントなコンパクション** - 何が消えたかを知らずに情報が失われる
4. **メタ知識の欠如** - 「誰が何を知っているか」の組織知がない

### 人間の組織が持つ「見えないインフラ」

人間の組織は以下を持っている：

- 共有された暗黙知と文化
- 永続的なアイデンティティと関係性
- 非同期だが永続的な「組織の記憶」
- 「あれ、おかしいな」と気づける違和感センサー

## 核心的な洞察

```
永続的なのはエージェント本体ではなく、外部メモリ

エージェント本体：毎回生まれ変わる（ステートレス）
外部メモリ：永続的（ステートフル）
アイデンティティ：外部メモリが担う
```

## アーキテクチャの特徴

### 1. 脳のLTP（長期増強）に学ぶ強度管理

情報が参照されたら、その情報自体の強度カウンターがインクリメントされる。「Use it or lose it」をソフトウェアで実現。

```python
# 2段階の強化プロセス
# Stage 1: 検索候補になった → candidate_count++（軽いカウント）
# Stage 2: 実際に使用された → access_count++, strength += 0.1（本格的な強化）
```

### 2. 睡眠フェーズによる記憶整理

脳の睡眠中の記憶整理プロセス（Synaptic Homeostasis Hypothesis）を模倣。

- 全体を見ずに局所的なルールで整理
- グローバルダウンスケーリング（一律減衰）
- 最近アクセスされたものは減衰を相殺

### 3. 観点（Perspective）による構造化

各エージェントは役割に応じた観点を持ち、学びを構造化して保存。

```json
{
  "agent_id": "procurement_agent_01",
  "perspectives": ["コスト", "納期", "サプライヤー", "品質", "代替"],
  "strength_by_perspective": {
    "コスト": 2.1,
    "納期": 0.8,
    "サプライヤー": 1.5
  }
}
```

### 4. 検索の2段階構造

```
Stage 1: 関連性フィルタ（ベクトル検索）
    → 無関係な情報を除外

Stage 2: 優先度ランキング（スコア合成）
    → 類似度 0.40 + 強度 0.40 + 新鮮さ 0.20
```

### 5. 教育プロセス

人間の教育と同じプロセスで専門性を形成：

```
教科書 → チャンク分割して読む → テスト → 睡眠（減衰） → 繰り返し
```

## 全体構成

```
┌─────────────────────────────────────────────────────────────┐
│  入力処理層（軽量LLM: Haiku等）                              │
├─────────────────────────────────────────────────────────────┤
│  大きな入力 → 機械的分割 → 要点抽出 → 概要生成              │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  オーケストレーター                                          │
├─────────────────────────────────────────────────────────────┤
│  概要のみ読んでルーティング判断                              │
│  専用外部メモリ：エージェント専門性、担当履歴、負荷状況     │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  専門エージェント群                                          │
├─────────────────────────────────────────────────────────────┤
│  各エージェント：                                            │
│  ├── 役割定義（調達、品質、顧客対応等）                     │
│  ├── 観点定義（役割に応じた5つ程度）                        │
│  ├── 専用外部メモリ（強度付き）                             │
│  └── インデックスメモ（コンテキスト内、ポインタ）           │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  睡眠フェーズ（定期バッチ）                                  │
├─────────────────────────────────────────────────────────────┤
│  タスク受付停止 → 減衰処理 → アーカイブ → タスク受付再開    │
└─────────────────────────────────────────────────────────────┘
```

## 技術スタック

すべて既存技術で実装可能。革新的な新技術は不要。

| 要素 | 既存技術 |
|------|---------|
| ベクトルDB | Pinecone, Qdrant, Chroma等 |
| メタデータ管理 | PostgreSQL, MySQL等 |
| LLM API | Claude, GPT等 |
| 定期バッチ処理 | cron, Cloud Scheduler等 |
| オーケストレーション | Python, LangGraph等 |

## 実装工数の見積もり

| フェーズ | 内容 |
|---------|------|
| PoC | 単一エージェント、基本的な強化/減衰、動作確認 |
| 実用レベル | 複数エージェント、パラメータ調整、エラーハンドリング、運用監視 |
| 教育プロセス | 教科書構造の設計、テスト問題作成、復習スケジュール |

## Google Titan との関係

GoogleのTitanアーキテクチャはテスト時にパラメータを更新する仕組みを持つが、まだ研究段階。

本アーキテクチャは「Titanが実用化されるまでの現実的な解」として位置づけられる。パラメータを書き換えない限り本当の意味での「専門性の内面化」はできないが、外部メモリの蓄積と強度管理により、**今より大幅に良い**状態は実現できる。

## ドキュメント

詳細な設計については [docs/architecture.ja.md](docs/architecture.ja.md) を参照。

## 背景

このアーキテクチャ設計は、2025年1月11日にClaude Opus 4.5との議論を通じて生まれた。LLMエージェントの本質的な限界について深く考察し、人間の組織や脳科学の知見を参考に、現在の技術で実装可能な解決策を設計した。

## ライセンス

MIT License - 詳細は [LICENSE](LICENSE) を参照。

## Contributing

このプロジェクトはまだアイデア段階です。実装に興味がある方、フィードバックをお持ちの方は、Issueを作成してください。
